{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ae75b-7e5e-4aaa-9012-d01cdc4c3d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d6ccf-45fc-447b-97aa-86b8216ab120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from ollama import chat\n",
    "from ollama import generate\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db3524-5b9d-428b-ae9d-896767eac39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede322e-7e71-4249-a9ca-d96449937ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ddl_redmine.txt', 'r') as file:\n",
    "with open('ddl_redmine_old.txt', 'r') as file:\n",
    "    ddl = file.read()\n",
    "response_ollama = generate(\n",
    "    model=\"deepseek-r1:32b\",\n",
    "    prompt=\"Покажи количество задач в статусе Новый и В разработке для пользователя Воронов Алексей\",\n",
    "    system=ddl,\n",
    "    # options={'temperature': 0.1,\n",
    "    #         \"top_p\": 0.3,\n",
    "    #         \"top_k\": 20,\n",
    "            # \"repeat_penalty\": 1.2,\n",
    "            # \"max_tokens\": 1024,\n",
    "            # \"presence_penalty\": 0.1,\n",
    "            # \"frequency_penalty\": 0.1\n",
    "            # }\n",
    ")\n",
    "response = response_ollama['response']\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb60df2-eda0-4b57-a768-76f0d87d21e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3bc86-770a-40e9-8d4d-7431cba3e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abb579-254c-4f9e-9686-ebc0a1a27cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ddl_redmine.txt', 'r') as file:\n",
    "with open('ddl_redmine_old.txt', 'r') as file:\n",
    "    ddl = file.read()\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": ddl})\n",
    "# messages.append({\"role\": \"user\", \"content\": \"Покажи количество задач в статусе Новый и В разработке которые назначены на пользователя Воронов Алексей\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Количество закрытых задач помесячно в 2024\"})\n",
    "# messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "# messages.append({\"role\": \"user\", \"content\": \"Исправь ошибку: \" + err})\n",
    "# messages.append({\"role\": \"assistant\", \"content\": assistant2})\n",
    "# messages.append({\"role\": \"user\", \"content\": \"Исправь ошибку и покажи только один исправленный sql: \" + err2})\n",
    "response_ollama: ChatResponse = chat(\n",
    "                                    model=\"deepseek-r1:14b\",\n",
    "                                    # model=\"qwq\",\n",
    "                                    # model=\"codellama:34b\",\n",
    "                                     messages=messages, \n",
    "                                     options={\n",
    "                                        'num_ctx': 8096, \n",
    "                                        'temperature': 0.1, \n",
    "                                        'top_p': 0.95\n",
    "                                    }\n",
    "                                    )\n",
    "response = response_ollama.message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08260277-e4c8-446e-b0a7-c9346bc958a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Хм, мне нужно решить, как получить количество закрытых задач помесячно в 2024 году из базы данных Redmine. \n",
      "\n",
      "Сначала я посмотрю на таблицы, которые у нас есть. Основная таблица — Issue — содержит информацию о задачах. В ней есть столбец CompletionDate, который указывает дату, когда задача была завершена.\n",
      "\n",
      "Мне нужно фильтровать только те задачи, у которых_completion_date_ falls in 2024. Затем я должен группировать их по месяцам и подсчитывать количество.\n",
      "\n",
      "Я подумаю о том, как ограничить дату 2024 года. Для этого можно использовать BETWEEN '2024-01-01' AND '2024-12-31'.\n",
      "\n",
      "Далее, я использую функцию DATE_FORMAT на CompletionDate с форматом '%Y-%m', чтобы получить год и месяц в виде строки. Это поможет группировать данные по месяцам.\n",
      "\n",
      "Запрос будет использовать COUNT(*) для подсчета количества задач. Я также убедюсь, что CompletionDate неisNull(), так как только завершенные задачи будут учтены.\n",
      "\n",
      "Теперь я сформирую SQL-запрос: SELECT с указанием COUNT(*), GROUP BY по DATE_FORMAT(CompletionDate, '%Y-%m'), иHAVING CompletionDate между датами 2024 года. Также добавлю ORDER BY для упорядочивания месяцев.\n",
      "\n",
      "Проверю, нет ли ошибок в синтаксисе, и убедюсь, что все условия правильно указаны.\n",
      "</think>\n",
      "\n",
      "```sql\n",
      "SELECT DATE_FORMAT(CompletionDate, '%Y-%m') AS Month, COUNT(*) AS Count \n",
      "FROM redmine.Issue \n",
      "WHERE CompletionDate IS NOT NULL \n",
      "  AND CompletionDate >= '2024-01-01' \n",
      "  AND CompletionDate <= '2024-12-31' \n",
      "GROUP BY DATE_FORMAT(CompletionDate, '%Y-%m') \n",
      "ORDER BY Month;\n",
      "```"
     ]
    }
   ],
   "source": [
    "# with open('ddl_redmine.txt', 'r') as file:\n",
    "with open('ddl_redmine_old.txt', 'r') as file:\n",
    "    ddl = file.read()\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": ddl})\n",
    "# messages.append({\"role\": \"user\", \"content\": \"Покажи количество задач в статусе Новый и В разработке которые назначены на пользователя Воронов Алексей\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Количество закрытых задач помесячно в 2024\"})\n",
    "stream_sql = chat(stream=True, \n",
    "                  # model='qwq',\n",
    "                  model='deepseek-r1:14b', \n",
    "                  messages=messages, \n",
    "                  options={\n",
    "                    'num_ctx': 8096, \n",
    "                    'temperature': 0.1, \n",
    "                    'top_p': 0.95\n",
    "                })\n",
    "response = ''\n",
    "for chunk in stream_sql:\n",
    "    print(chunk['message']['content'], end='', flush=True)\n",
    "    response += chunk['message']['content']\n",
    "# print(\"=====================\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b11a21-37a2-467c-830e-066775928754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84203009-1f43-4da9-be43-bc69ab187d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chart.txt', 'r') as file:\n",
    "    chart = file.read()\n",
    "\n",
    "json = \"\"\"[{\n",
    "    \"новые\": 50,\n",
    "    \"разработка\": 23\n",
    "}]\"\"\"\n",
    "# json = '[]'\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": chart})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Покажи количество задач в статусе Новый и В разработке для пользователя Воронов Алексей\\n\" + json})\n",
    "\n",
    "\n",
    "response_chart_ollama: ChatResponse = chat(model=\"deepseek-r1:32b\", messages=messages)\n",
    "response_chart = response_chart_ollama.message.content\n",
    "print(response_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09fb10-a04f-403d-916c-611ede845b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1426d7a-6e66-48e4-83d0-8050147e00c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e19c7-7ab5-4e0f-a5a8-b7531a1d72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "API_URL = 'https://api.proxyapi.ru/anthropic'\n",
    "# API_URL = 'https://api.proxyapi.ru/openai/v1/chat/completions'\n",
    "API_KEY = ''\n",
    "\n",
    "client = Anthropic(\n",
    "    base_url=API_URL,\n",
    "    api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90844346-4261-4f1e-a7a5-5e1685e59a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"Привет. Ты кто?\",\n",
    "            \"role\": \"assistant\", \"content\": \"Привет! Я Assistant, искусственный интеллект, разработанный Anthropic для помощи людям. Я могу отвечать на вопросы, предоставлять информацию и помогать с различными задачами. Как я могу помочь вам сегодня?\",\n",
    "            \"role\": \"user\", \"content\": \"Какую последнюю версию chart.js ты знаешь?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    ")\n",
    "print('------------------------------------')\n",
    "print(message)\n",
    "print('------------------------------------')\n",
    "print(message.content[0].text)\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ca1fe-69ee-4103-857e-78dc51ddcd39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0559c26-173e-4228-b99c-cd30857f0060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe15814-cd14-4452-9c2b-51c5b604f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_URL = 'https://api.proxyapi.ru/deepseek'\n",
    "API_KEY = ''\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=API_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690790ab-3e10-4c17-a11a-ca5fb6fc7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    # model='deepseek-reasoner',\n",
    "    model='deepseek-chat',\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"Ты ассистент по вопросам строительства. Тебя зовут Михаил.\",\n",
    "            \"role\": \"user\", \"content\": \"Привет. Как тебя зовут?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print('------------------------------------')\n",
    "print(response)\n",
    "print('------------------------------------')\n",
    "print(response.choices[0].message.content)\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e446a-b0f6-4787-9c1f-29436ebb50ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015695a3-47c6-45f9-bdbd-ffaf69a963a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3d559-f671-41c5-be8d-39a6874edbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba654d-90fa-45f3-af2f-56695c1fbfda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de84b8-a696-4706-b7de-76f0598225e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566bc70-39b6-4cb1-a526-e576744e9014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec27a1-37c4-4ab8-b2f8-39288cde0be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58ac32-8635-4cef-87a6-ccbdb39a9cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10974f7-060c-4a76-9d6e-db4ca0350f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd7fcc-8812-4415-9ccf-15a3bc36c1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010a677-6a57-4d75-8464-1a1b52a50447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7b5d0-13cf-4246-9847-9d48e572b303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d44090-6b65-47c1-8bc6-cc26453916a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287ddef-7868-4d1d-b4f9-dba8ce88dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39dc40b-2346-42d1-b0fd-179e3dd91aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f270867-bcea-460c-9b97-b7fc9cf8b63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ollama_env)",
   "language": "python",
   "name": "ollama_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
